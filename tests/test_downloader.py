#!/usr/bin/env python3
"""
æµ‹è¯•æ”¹è¿›åçš„ FilingDownloader
ä¸“é—¨æµ‹è¯• Ford å’Œå…¶ä»–å¤±è´¥æ¡ˆä¾‹
"""
import asyncio
import sys
from pathlib import Path
from datetime import datetime

# Add the project root to Python path
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.core.database import SessionLocal
from app.models.filing import Filing, ProcessingStatus
from app.services.filing_downloader import filing_downloader


async def test_specific_filing(filing_id: int = None, accession_number: str = None):
    """æµ‹è¯•ç‰¹å®šçš„è´¢æŠ¥ä¸‹è½½"""
    db = SessionLocal()
    
    try:
        # è·å–è´¢æŠ¥
        if filing_id:
            filing = db.query(Filing).filter(Filing.id == filing_id).first()
        elif accession_number:
            filing = db.query(Filing).filter(Filing.accession_number == accession_number).first()
        else:
            # é»˜è®¤æµ‹è¯• Ford çš„æ¡ˆä¾‹
            filing = db.query(Filing).filter(
                Filing.accession_number == "0000037996-25-000141"
            ).first()
        
        if not filing:
            print("âŒ æ‰¾ä¸åˆ°æŒ‡å®šçš„è´¢æŠ¥")
            return
        
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•è´¢æŠ¥ä¸‹è½½ - {filing.company.ticker} {filing.filing_type.value}")
        print(f"Accession: {filing.accession_number}")
        print(f"{'='*60}\n")
        
        # é‡ç½®çŠ¶æ€
        filing.status = ProcessingStatus.PENDING
        filing.error_message = None
        db.commit()
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = datetime.now()
        
        # æ‰§è¡Œä¸‹è½½
        success = await filing_downloader.download_filing(db, filing)
        
        # è®¡ç®—è€—æ—¶
        duration = (datetime.now() - start_time).total_seconds()
        
        # æ£€æŸ¥ç»“æœ
        filing_dir = filing_downloader._get_filing_directory(filing)
        
        print(f"\nğŸ“Š ä¸‹è½½ç»“æœ:")
        print(f"â”œâ”€â”€ çŠ¶æ€: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
        print(f"â”œâ”€â”€ è€—æ—¶: {duration:.2f} ç§’")
        print(f"â”œâ”€â”€ FilingçŠ¶æ€: {filing.status.value}")
        print(f"â”œâ”€â”€ é”™è¯¯ä¿¡æ¯: {filing.error_message or 'æ— '}")
        print(f"â””â”€â”€ æ–‡æ¡£URL: {filing.primary_doc_url or 'æœªè®¾ç½®'}")
        
        if filing_dir.exists():
            files = list(filing_dir.glob("*"))
            print(f"\nğŸ“ ä¸‹è½½çš„æ–‡ä»¶ ({len(files)} ä¸ª):")
            for file in sorted(files):
                size_kb = file.stat().st_size / 1024
                print(f"â”œâ”€â”€ {file.name} ({size_kb:.1f} KB)")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ iXBRL viewer
                if file.suffix in ['.htm', '.html']:
                    content = file.read_text(errors='ignore')[:500]
                    if 'loadViewer' in content:
                        print(f"    âš ï¸  æ£€æµ‹åˆ° iXBRL Viewer é¡µé¢")
            
            # ç‰¹åˆ«æ£€æŸ¥ä¸»æ–‡æ¡£
            main_doc = filing_downloader.get_filing_path(filing)
            if main_doc and main_doc.name != 'index.htm':
                print(f"\nâœ… æ‰¾åˆ°ä¸»æ–‡æ¡£: {main_doc.name}")
                
                # è¯»å–å‰1000ä¸ªå­—ç¬¦æ£€æŸ¥å†…å®¹
                content = main_doc.read_text(errors='ignore')[:1000]
                if filing.company.name in content or filing.company.ticker in content:
                    print("âœ… æ–‡æ¡£åŒ…å«å…¬å¸ä¿¡æ¯")
                if 'financial' in content.lower() or 'revenue' in content.lower():
                    print("âœ… æ–‡æ¡£åŒ…å«è´¢åŠ¡ç›¸å…³å†…å®¹")
            else:
                print("\nâŒ æœªæ‰¾åˆ°ä¸»æ–‡æ¡£ï¼ˆåªæœ‰ index.htmï¼‰")
        
        return success
        
    finally:
        db.close()


async def test_failed_cases():
    """æµ‹è¯•å¤šä¸ªå¤±è´¥æ¡ˆä¾‹"""
    db = SessionLocal()
    
    # è·å–ä¸€äº›å¤±è´¥çš„æ¡ˆä¾‹
    failed_filings = db.query(Filing).filter(
        Filing.status.in_([ProcessingStatus.FAILED, ProcessingStatus.PENDING])
    ).limit(5).all()
    
    print(f"\nğŸ” æ‰¾åˆ° {len(failed_filings)} ä¸ªå¤±è´¥/å¾…å¤„ç†çš„è´¢æŠ¥")
    
    results = []
    for filing in failed_filings:
        print(f"\n{'='*60}")
        print(f"æµ‹è¯• {filing.company.ticker} - {filing.accession_number}")
        
        success = await test_specific_filing(filing_id=filing.id)
        results.append({
            'ticker': filing.company.ticker,
            'accession': filing.accession_number,
            'success': success
        })
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        await asyncio.sleep(1)
    
    # æ±‡æ€»ç»“æœ
    print(f"\n\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•æ±‡æ€»:")
    print(f"{'='*60}")
    
    success_count = sum(1 for r in results if r['success'])
    print(f"æˆåŠŸç‡: {success_count}/{len(results)} ({success_count/len(results)*100:.1f}%)")
    
    print("\nè¯¦ç»†ç»“æœ:")
    for r in results:
        status = "âœ…" if r['success'] else "âŒ"
        print(f"{status} {r['ticker']} - {r['accession']}")
    
    db.close()


async def check_file_statistics():
    """æ£€æŸ¥æ‰€æœ‰è´¢æŠ¥çš„æ–‡ä»¶ç»Ÿè®¡"""
    db = SessionLocal()
    
    all_filings = db.query(Filing).all()
    
    stats = {
        'total': len(all_filings),
        'has_main_doc': 0,
        'only_index': 0,
        'no_files': 0,
        'avg_file_size': []
    }
    
    print(f"\nğŸ“Š æ­£åœ¨åˆ†æ {len(all_filings)} ä¸ªè´¢æŠ¥çš„æ–‡ä»¶...")
    
    for filing in all_filings:
        filing_dir = filing_downloader._get_filing_directory(filing)
        
        if not filing_dir.exists():
            stats['no_files'] += 1
            continue
        
        files = list(filing_dir.glob("*"))
        non_index_files = [f for f in files if f.name != 'index.htm']
        
        if non_index_files:
            stats['has_main_doc'] += 1
            # è®°å½•ä¸»æ–‡æ¡£å¤§å°
            main_doc = max(non_index_files, key=lambda f: f.stat().st_size)
            stats['avg_file_size'].append(main_doc.stat().st_size)
        elif files:
            stats['only_index'] += 1
    
    # è®¡ç®—å¹³å‡å¤§å°
    avg_size = sum(stats['avg_file_size']) / len(stats['avg_file_size']) if stats['avg_file_size'] else 0
    
    print(f"\nğŸ“ˆ æ–‡ä»¶ç»Ÿè®¡ç»“æœ:")
    print(f"â”œâ”€â”€ æ€»è´¢æŠ¥æ•°: {stats['total']}")
    print(f"â”œâ”€â”€ æœ‰ä¸»æ–‡æ¡£: {stats['has_main_doc']} ({stats['has_main_doc']/stats['total']*100:.1f}%)")
    print(f"â”œâ”€â”€ åªæœ‰index: {stats['only_index']} ({stats['only_index']/stats['total']*100:.1f}%)")
    print(f"â”œâ”€â”€ æ— æ–‡ä»¶: {stats['no_files']} ({stats['no_files']/stats['total']*100:.1f}%)")
    print(f"â””â”€â”€ ä¸»æ–‡æ¡£å¹³å‡å¤§å°: {avg_size/1024:.1f} KB")
    
    db.close()


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Fintellic ä¸‹è½½å™¨æµ‹è¯•å·¥å…·")
    print("="*60)
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "stats":
            # ç»Ÿè®¡æ¨¡å¼
            await check_file_statistics()
        elif sys.argv[1] == "all":
            # æµ‹è¯•æ‰€æœ‰å¤±è´¥æ¡ˆä¾‹
            await test_failed_cases()
        else:
            # æµ‹è¯•ç‰¹å®šçš„ accession number
            await test_specific_filing(accession_number=sys.argv[1])
    else:
        # é»˜è®¤æµ‹è¯• Ford æ¡ˆä¾‹
        print("æµ‹è¯• Ford çš„å¤±è´¥æ¡ˆä¾‹ (0000037996-25-000141)")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python tests/test_downloader.py [accession-number]  # æµ‹è¯•ç‰¹å®šè´¢æŠ¥")
        print("  python tests/test_downloader.py all                 # æµ‹è¯•æ‰€æœ‰å¤±è´¥æ¡ˆä¾‹")
        print("  python tests/test_downloader.py stats               # æŸ¥çœ‹æ–‡ä»¶ç»Ÿè®¡")
        print()
        
        await test_specific_filing(accession_number="0000037996-25-000141")


if __name__ == "__main__":
    asyncio.run(main())
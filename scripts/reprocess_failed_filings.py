#!/usr/bin/env python3
"""
é‡æ–°å¤„ç†å¤±è´¥å’Œå¡ä½çš„è´¢æŠ¥
åŒ…æ‹¬ï¼šFAILED, PENDING, PARSING, DOWNLOADING çŠ¶æ€çš„è´¢æŠ¥
FIXED: å¤„ç†tickerä¸ºNoneçš„æƒ…å†µ
NEW: æ·»åŠ æŒ‰æ—¥æœŸé‡æ–°å¤„ç†æ‰€æœ‰è´¢æŠ¥çš„åŠŸèƒ½ï¼ˆé€‰é¡¹6å’Œå‘½ä»¤è¡Œå‚æ•°ï¼‰
"""

import asyncio
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from sqlalchemy.orm import Session
from app.core.database import SessionLocal
from app.models.filing import Filing, ProcessingStatus
from app.tasks.filing_tasks import process_filing_task
from datetime import datetime, timedelta
import logging
import argparse

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def get_failed_filings(db: Session):
    """è·å–æ‰€æœ‰å¤±è´¥çš„è´¢æŠ¥"""
    return db.query(Filing).filter(
        Filing.status == ProcessingStatus.FAILED
    ).all()


def get_pending_filings(db: Session):
    """è·å–æ‰€æœ‰å¾…å¤„ç†çš„è´¢æŠ¥"""
    return db.query(Filing).filter(
        Filing.status == ProcessingStatus.PENDING
    ).all()


def get_stuck_filings(db: Session, stuck_minutes=30):
    """è·å–å¡ä½çš„è´¢æŠ¥ï¼ˆparsingæˆ–downloadingçŠ¶æ€è¶…è¿‡æŒ‡å®šæ—¶é—´ï¼‰"""
    stuck_time = datetime.utcnow() - timedelta(minutes=stuck_minutes)
    
    stuck_filings = db.query(Filing).filter(
        Filing.status.in_([ProcessingStatus.PARSING, ProcessingStatus.DOWNLOADING])
    ).all()
    
    # è¿‡æ»¤å‡ºçœŸæ­£å¡ä½çš„ï¼ˆå¤„ç†æ—¶é—´è¿‡é•¿çš„ï¼‰
    truly_stuck = []
    for filing in stuck_filings:
        if filing.processing_started_at:
            # å¤„ç†æ—¶åŒºé—®é¢˜
            if filing.processing_started_at.tzinfo is None:
                # naive datetimeï¼Œå‡è®¾æ˜¯UTC
                processing_started_utc = filing.processing_started_at
            else:
                # aware datetimeï¼Œè½¬æ¢ä¸ºUTC
                processing_started_utc = filing.processing_started_at.replace(tzinfo=None)
            
            if processing_started_utc < stuck_time:
                truly_stuck.append(filing)
        else:
            # æ²¡æœ‰å¼€å§‹æ—¶é—´ä½†çŠ¶æ€æ˜¯processingï¼Œä¹Ÿç®—å¡ä½
            truly_stuck.append(filing)
    
    return truly_stuck


def get_incomplete_filings(db: Session):
    """è·å–å†…å®¹ä¸å®Œæ•´çš„è´¢æŠ¥"""
    completed = db.query(Filing).filter(
        Filing.status == ProcessingStatus.COMPLETED
    ).all()
    
    incomplete = []
    for filing in completed:
        # æ£€æŸ¥æ˜¯å¦æœ‰åŸºæœ¬çš„åˆ†æå†…å®¹
        has_content = False
        
        # æ£€æŸ¥æ–°ç‰ˆç»Ÿä¸€åˆ†æ
        if filing.unified_analysis and len(filing.unified_analysis) > 100:
            has_content = True
        # æ£€æŸ¥æ—§ç‰ˆAIæ‘˜è¦
        elif filing.ai_summary and len(filing.ai_summary) > 100:
            has_content = True
        
        if not has_content:
            incomplete.append(filing)
    
    return incomplete


def get_filings_by_date(db: Session, target_date: datetime):
    """
    NEW: è·å–æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰è´¢æŠ¥ï¼ˆåŸºäº detected_at - ç³»ç»Ÿæ£€æµ‹æ—¶é—´ï¼‰
    Args:
        db: æ•°æ®åº“ä¼šè¯
        target_date: ç›®æ ‡æ—¥æœŸï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸² 'YYYY-MM-DD' æˆ– datetime å¯¹è±¡ï¼‰
    Returns:
        è¯¥æ—¥æœŸçš„æ‰€æœ‰ filing åˆ—è¡¨
    """
    from sqlalchemy import func
    
    # å¦‚æœä¼ å…¥çš„æ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸º datetime
    if isinstance(target_date, str):
        try:
            target_date = datetime.strptime(target_date, '%Y-%m-%d')
        except ValueError:
            logger.error(f"Invalid date format: {target_date}. Expected YYYY-MM-DD")
            return []
    
    # ä½¿ç”¨ DATE() å‡½æ•°ç›´æ¥æ¯”è¾ƒæ—¥æœŸéƒ¨åˆ†ï¼ˆå¿½ç•¥æ—¶åŒºé—®é¢˜ï¼‰
    date_str = target_date.strftime('%Y-%m-%d')
    
    filings = db.query(Filing).filter(
        func.date(Filing.detected_at) == date_str
    ).order_by(Filing.detected_at.desc()).all()
    
    return filings


async def reprocess_filing(filing_id: int):
    """é‡æ–°å¤„ç†å•ä¸ªè´¢æŠ¥"""
    try:
        logger.info(f"Queueing filing ID {filing_id} for reprocessing")
        process_filing_task.delay(filing_id)
        return True
    except Exception as e:
        logger.error(f"Error reprocessing filing {filing_id}: {e}")
        return False


def get_display_ticker(filing):
    """è·å–ç”¨äºæ˜¾ç¤ºçš„tickerï¼Œå¤„ç†Noneçš„æƒ…å†µ"""
    if filing.ticker:
        return filing.ticker
    elif filing.company and filing.company.ticker:
        return filing.company.ticker
    elif filing.company and filing.company.cik:
        # å¯¹äºæ²¡æœ‰tickerçš„å…¬å¸ï¼ˆå¦‚S-1ï¼‰ï¼Œæ˜¾ç¤ºCIKå4ä½
        return f"CIK-{filing.company.cik[-4:]}"
    else:
        return "N/A"


def get_company_name(filing):
    """è·å–å…¬å¸åç§°ï¼Œå¤„ç†Noneçš„æƒ…å†µ"""
    if filing.company and filing.company.name:
        # æˆªå–å‰20ä¸ªå­—ç¬¦
        return filing.company.name[:20]
    else:
        return "Unknown"


def display_filings_by_date_stats(filings, target_date):
    """
    NEW: æ˜¾ç¤ºæŒ‡å®šæ—¥æœŸè´¢æŠ¥çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŸºäº detected_atï¼‰
    """
    if not filings:
        print(f"\nâŒ {target_date.strftime('%Y-%m-%d')} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è´¢æŠ¥")
        return
    
    print(f"\nğŸ“Š {target_date.strftime('%Y-%m-%d')} çš„è´¢æŠ¥ç»Ÿè®¡ (åŸºäºç³»ç»Ÿæ£€æµ‹æ—¶é—´):")
    print("="*80)
    
    # ç»Ÿè®¡å„çŠ¶æ€æ•°é‡
    status_counts = {}
    for filing in filings:
        status = filing.status.value
        status_counts[status] = status_counts.get(status, 0) + 1
    
    # ç»Ÿè®¡å„ç±»å‹æ•°é‡
    type_counts = {}
    for filing in filings:
        ftype = filing.filing_type.value
        type_counts[ftype] = type_counts.get(ftype, 0) + 1
    
    print(f"\næ€»æ•°: {len(filings)} ä¸ªè´¢æŠ¥")
    
    print(f"\næŒ‰çŠ¶æ€åˆ†å¸ƒ:")
    for status, count in sorted(status_counts.items()):
        print(f"  â€¢ {status}: {count} ä¸ª")
    
    print(f"\næŒ‰ç±»å‹åˆ†å¸ƒ:")
    for ftype, count in sorted(type_counts.items()):
        print(f"  â€¢ {ftype}: {count} ä¸ª")
    
    # æ˜¾ç¤ºå‰10ä¸ªè´¢æŠ¥è¯¦æƒ…
    print(f"\nå‰ 10 ä¸ªè´¢æŠ¥è¯¦æƒ…:")
    print("-" * 100)
    print(f"{'ID':<8} {'Ticker':<10} {'Type':<8} {'Detected Time':<16} {'Status':<15} {'Has Analysis':<15}")
    print("-" * 100)
    
    for filing in filings[:10]:
        display_ticker = get_display_ticker(filing)
        has_analysis = "âœ“ Yes" if (filing.unified_analysis and len(filing.unified_analysis) > 100) else "âœ— No"
        detected_time = filing.detected_at.strftime('%H:%M:%S') if filing.detected_at else "N/A"
        
        print(f"{filing.id:<8} {display_ticker:<10} {filing.filing_type.value:<8} "
              f"{detected_time:<16} {filing.status.value:<15} {has_analysis:<15}")
    
    if len(filings) > 10:
        print(f"\n... è¿˜æœ‰ {len(filings) - 10} ä¸ªè´¢æŠ¥")
    
    print("-" * 100)


async def main():
    """ä¸»å‡½æ•°"""
    # NEW: æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ
    parser = argparse.ArgumentParser(
        description='é‡æ–°å¤„ç†è´¢æŠ¥ - æ”¯æŒæŒ‰çŠ¶æ€æˆ–æŒ‰æ—¥æœŸå¤„ç†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # äº¤äº’å¼æ¨¡å¼ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
  python scripts/reprocess_failed_filings.py
  
  # æŒ‰æ—¥æœŸé‡æ–°å¤„ç†æ‰€æœ‰è´¢æŠ¥
  python scripts/reprocess_failed_filings.py --date 2025-10-27
  
  # æŒ‰æ—¥æœŸé‡æ–°å¤„ç†ï¼Œåªå¤„ç†å·²å®Œæˆçš„è´¢æŠ¥
  python scripts/reprocess_failed_filings.py --date 2025-10-27 --completed-only
        """
    )
    parser.add_argument(
        '--date',
        type=str,
        help='æŒ‰æ—¥æœŸé‡æ–°å¤„ç†æ‰€æœ‰è´¢æŠ¥ (æ ¼å¼: YYYY-MM-DDï¼Œä¾‹å¦‚: 2025-10-27)'
    )
    parser.add_argument(
        '--completed-only',
        action='store_true',
        help='åªé‡æ–°å¤„ç†å·²å®ŒæˆçŠ¶æ€çš„è´¢æŠ¥ï¼ˆé…åˆ --date ä½¿ç”¨ï¼‰'
    )
    
    args = parser.parse_args()
    
    db = SessionLocal()
    
    try:
        # NEW: å¦‚æœæä¾›äº† --date å‚æ•°ï¼Œç›´æ¥å¤„ç†è¯¥æ—¥æœŸçš„è´¢æŠ¥
        if args.date:
            try:
                target_date = datetime.strptime(args.date, '%Y-%m-%d')
            except ValueError:
                print(f"\nâŒ é”™è¯¯: æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ã€‚è¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ï¼Œä¾‹å¦‚: 2025-10-27")
                return
            
            print("\n" + "="*80)
            print(f"ğŸ“… æŒ‰æ—¥æœŸé‡æ–°å¤„ç†è´¢æŠ¥: {args.date}")
            print("="*80)
            
            # è·å–è¯¥æ—¥æœŸçš„æ‰€æœ‰è´¢æŠ¥
            filings = get_filings_by_date(db, target_date)
            
            if not filings:
                print(f"\nâŒ {args.date} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è´¢æŠ¥")
                return
            
            # å¦‚æœæŒ‡å®šäº† --completed-onlyï¼Œåªä¿ç•™å·²å®Œæˆçš„
            if args.completed_only:
                filings = [f for f in filings if f.status == ProcessingStatus.COMPLETED]
                print(f"\nâœ“ åªå¤„ç†å·²å®ŒæˆçŠ¶æ€çš„è´¢æŠ¥")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            display_filings_by_date_stats(filings, target_date)
            
            # ç¡®è®¤æ˜¯å¦ç»§ç»­
            print(f"\nâš ï¸  å³å°†é‡æ–°å¤„ç† {len(filings)} ä¸ªè´¢æŠ¥")
            print(f"   è¿™å°†é‡ç½®å®ƒä»¬çš„çŠ¶æ€å¹¶é‡æ–°è¿è¡Œ AI åˆ†æ")
            response = input("\nç¡®è®¤ç»§ç»­? (y/n): ")
            if response.lower() != 'y':
                print("âŒ å·²å–æ¶ˆ")
                return
            
            # é‡æ–°å¤„ç†
            print("\nğŸš€ å¼€å§‹é‡æ–°å¤„ç†...")
            success_count = 0
            
            for i, filing in enumerate(filings, 1):
                try:
                    # é‡ç½®çŠ¶æ€ä¸ºPENDING
                    filing.status = ProcessingStatus.PENDING
                    filing.error_message = None
                    filing.retry_count = 0
                    filing.processing_started_at = None
                    filing.processing_completed_at = None
                    
                    # å¯é€‰ï¼šæ¸…ç©ºåˆ†æå†…å®¹ï¼Œå¼ºåˆ¶é‡æ–°åˆ†æ
                    filing.unified_analysis = None
                    filing.analysis_version = None
                    
                    db.commit()
                    
                    # åŠ å…¥å¤„ç†é˜Ÿåˆ—
                    await reprocess_filing(filing.id)
                    
                    display_ticker = get_display_ticker(filing)
                    print(f"  [{i}/{len(filings)}] âœ… {display_ticker} {filing.filing_type.value} "
                          f"(ID: {filing.id}) å·²åŠ å…¥é˜Ÿåˆ—")
                    success_count += 1
                    
                    # æ¯5ä¸ªæš‚åœä¸€ä¸‹ï¼Œé¿å…è¿‡è½½
                    if i % 5 == 0:
                        await asyncio.sleep(1)
                        
                except Exception as e:
                    display_ticker = get_display_ticker(filing)
                    print(f"  [{i}/{len(filings)}] âŒ {display_ticker} å¤„ç†å¤±è´¥: {e}")
            
            print("\n" + "="*80)
            print(f"âœ… å®Œæˆï¼æˆåŠŸåŠ å…¥é˜Ÿåˆ—: {success_count}/{len(filings)} ä¸ªè´¢æŠ¥")
            print("="*80)
            print("\nğŸ“Š åç»­ç›‘æ§:")
            print("  1. æŸ¥çœ‹çŠ¶æ€: python scripts/check_filing_status.py")
            print("  2. æŸ¥çœ‹æ—¥å¿—: tail -f logs/fintellic.log | grep -E 'ERROR|WARNING|succeeded'")
            
            return
        
        # åŸæœ‰çš„äº¤äº’å¼æµç¨‹ï¼ˆæ²¡æœ‰æä¾› --date å‚æ•°æ—¶ï¼‰
        print("\n" + "="*80)
        print("ğŸ“Š è´¢æŠ¥å¤„ç†çŠ¶æ€æ£€æŸ¥")
        print("="*80)
        
        # 1. è·å–å„ç§çŠ¶æ€çš„è´¢æŠ¥
        failed_filings = get_failed_filings(db)
        pending_filings = get_pending_filings(db)
        stuck_filings = get_stuck_filings(db, stuck_minutes=30)
        incomplete_filings = get_incomplete_filings(db)
        
        print(f"\nğŸ“ˆ å‘ç°çš„é—®é¢˜è´¢æŠ¥:")
        print(f"  â€¢ å¤±è´¥ (FAILED): {len(failed_filings)} ä¸ª")
        print(f"  â€¢ å¾…å¤„ç† (PENDING): {len(pending_filings)} ä¸ª")
        print(f"  â€¢ å¡ä½ (PARSING/DOWNLOADING >30åˆ†é’Ÿ): {len(stuck_filings)} ä¸ª")
        print(f"  â€¢ å†…å®¹ä¸å®Œæ•´ (COMPLETEDä½†æ— å†…å®¹): {len(incomplete_filings)} ä¸ª")
        
        # 2. åˆå¹¶æ‰€æœ‰éœ€è¦å¤„ç†çš„è´¢æŠ¥ï¼ˆå»é‡ï¼‰
        all_filings_dict = {}
        
        for filing in failed_filings:
            all_filings_dict[filing.id] = ('FAILED', filing)
        
        for filing in pending_filings:
            if filing.id not in all_filings_dict:
                all_filings_dict[filing.id] = ('PENDING', filing)
        
        for filing in stuck_filings:
            if filing.id not in all_filings_dict:
                all_filings_dict[filing.id] = ('STUCK', filing)
        
        for filing in incomplete_filings:
            if filing.id not in all_filings_dict:
                all_filings_dict[filing.id] = ('INCOMPLETE', filing)
        
        all_filings_to_reprocess = list(all_filings_dict.values())
        
        if not all_filings_to_reprocess:
            print("\nâœ… æ²¡æœ‰éœ€è¦é‡æ–°å¤„ç†çš„è´¢æŠ¥ï¼")
            # NEW: æç¤ºå¯ä»¥ä½¿ç”¨æ—¥æœŸé€‰é¡¹
            print("\nğŸ’¡ æç¤º: å¦‚æœè¦æŒ‰æ—¥æœŸé‡æ–°å¤„ç†è´¢æŠ¥ï¼Œå¯ä»¥ä½¿ç”¨:")
            print("   python scripts/reprocess_failed_filings.py --date YYYY-MM-DD")
            return
        
        # 3. æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        print(f"\nğŸ“‹ å°†è¦é‡æ–°å¤„ç† {len(all_filings_to_reprocess)} ä¸ªè´¢æŠ¥ï¼š")
        print("-" * 100)
        print(f"{'ID':<8} {'Ticker':<10} {'Type':<8} {'Date':<12} {'Current Status':<15} {'Issue':<30}")
        print("-" * 100)
        
        # æŒ‰é—®é¢˜ç±»å‹æ’åºæ˜¾ç¤º
        for reason, filing in sorted(all_filings_to_reprocess, key=lambda x: x[0]):
            issue_desc = {
                'FAILED': f"å¤„ç†å¤±è´¥: {(filing.error_message or 'Unknown')[:25]}",
                'PENDING': "ç­‰å¾…å¤„ç†",
                'STUCK': f"å¡åœ¨ {filing.status.value} çŠ¶æ€",
                'INCOMPLETE': "å·²å®Œæˆä½†æ— å†…å®¹"
            }.get(reason, reason)
            
            # FIXED: ä½¿ç”¨å®‰å…¨çš„æ–¹å¼è·å–ticker
            display_ticker = get_display_ticker(filing)
            
            print(f"{filing.id:<8} {display_ticker:<10} {filing.filing_type.value:<8} "
                  f"{filing.filing_date.strftime('%Y-%m-%d'):<12} "
                  f"{filing.status.value:<15} {issue_desc:<30}")
        
        print("-" * 100)
        
        # æ˜¾ç¤ºå¤±è´¥è´¢æŠ¥çš„è¯¦ç»†ä¿¡æ¯
        if failed_filings:
            print("\nğŸ“ å¤±è´¥è´¢æŠ¥è¯¦ç»†ä¿¡æ¯:")
            print("-" * 100)
            for filing in failed_filings[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                display_ticker = get_display_ticker(filing)
                company_name = get_company_name(filing)
                print(f"\nID: {filing.id}")
                print(f"  å…¬å¸: {company_name} ({display_ticker})")
                print(f"  ç±»å‹: {filing.filing_type.value}")
                print(f"  æ—¥æœŸ: {filing.filing_date.strftime('%Y-%m-%d')}")
                print(f"  é”™è¯¯: {filing.error_message or 'No error message'}")
                if filing.company:
                    print(f"  CIK: {filing.company.cik}")
                    print(f"  æ˜¯S-1: {'æ˜¯' if filing.filing_type.value == 'S-1' else 'å¦'}")
        
        # 4. æ˜¾ç¤ºå¤„ç†é€‰é¡¹
        print("\nğŸ”§ å¤„ç†é€‰é¡¹:")
        print("  1. å¤„ç†æ‰€æœ‰é—®é¢˜è´¢æŠ¥")
        print("  2. åªå¤„ç†å¤±è´¥çš„ (FAILED)")
        print("  3. åªå¤„ç†å¡ä½çš„ (STUCK)")
        print("  4. åªå¤„ç†å¾…å¤„ç†çš„ (PENDING)")
        print("  5. åªå¤„ç†å†…å®¹ä¸å®Œæ•´çš„")
        print("  6. æŒ‰æ—¥æœŸé‡æ–°å¤„ç†æ‰€æœ‰è´¢æŠ¥ (NEW)")
        print("  0. å–æ¶ˆ")
        
        choice = input("\nè¯·é€‰æ‹© (0-6): ").strip()
        
        if choice == '0':
            print("âŒ å·²å–æ¶ˆ")
            return
        elif choice == '2':
            filings_to_process = [(r, f) for r, f in all_filings_to_reprocess if r == 'FAILED']
        elif choice == '3':
            filings_to_process = [(r, f) for r, f in all_filings_to_reprocess if r == 'STUCK']
        elif choice == '4':
            filings_to_process = [(r, f) for r, f in all_filings_to_reprocess if r == 'PENDING']
        elif choice == '5':
            filings_to_process = [(r, f) for r, f in all_filings_to_reprocess if r == 'INCOMPLETE']
        elif choice == '6':
            # NEW: æŒ‰æ—¥æœŸé‡æ–°å¤„ç†
            date_input = input("\nè¯·è¾“å…¥æ—¥æœŸ (YYYY-MM-DDï¼Œä¾‹å¦‚ 2025-10-27): ").strip()
            try:
                target_date = datetime.strptime(date_input, '%Y-%m-%d')
            except ValueError:
                print("\nâŒ é”™è¯¯: æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ã€‚è¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                return
            
            print(f"\næ­£åœ¨æŸ¥è¯¢ {date_input} çš„è´¢æŠ¥...")
            date_filings = get_filings_by_date(db, target_date)
            
            if not date_filings:
                print(f"\nâŒ {date_input} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è´¢æŠ¥")
                return
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            display_filings_by_date_stats(date_filings, target_date)
            
            # è¯¢é—®æ˜¯å¦åªå¤„ç†å·²å®Œæˆçš„
            completed_only = input("\næ˜¯å¦åªé‡æ–°å¤„ç†å·²å®ŒæˆçŠ¶æ€çš„è´¢æŠ¥? (y/n): ").strip().lower()
            if completed_only == 'y':
                date_filings = [f for f in date_filings if f.status == ProcessingStatus.COMPLETED]
                print(f"\nâœ“ åªå¤„ç†å·²å®ŒæˆçŠ¶æ€çš„è´¢æŠ¥ï¼Œå…± {len(date_filings)} ä¸ª")
            
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            filings_to_process = [('DATE_REPROCESS', f) for f in date_filings]
        else:
            filings_to_process = all_filings_to_reprocess
        
        if not filings_to_process:
            print("âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è´¢æŠ¥")
            return
        
        # 5. æœ€ç»ˆç¡®è®¤
        print(f"\nâš ï¸  å³å°†é‡æ–°å¤„ç† {len(filings_to_process)} ä¸ªè´¢æŠ¥")
        response = input("ç¡®è®¤ç»§ç»­? (y/n): ")
        if response.lower() != 'y':
            print("âŒ å·²å–æ¶ˆ")
            return
        
        # 6. é‡ç½®çŠ¶æ€å¹¶é‡æ–°å¤„ç†
        print("\nğŸš€ å¼€å§‹é‡æ–°å¤„ç†...")
        
        for i, (reason, filing) in enumerate(filings_to_process, 1):
            try:
                # é‡ç½®çŠ¶æ€ä¸ºPENDING
                filing.status = ProcessingStatus.PENDING
                filing.error_message = None
                filing.retry_count = 0
                filing.processing_started_at = None
                filing.processing_completed_at = None
                
                # å¦‚æœæ˜¯æŒ‰æ—¥æœŸé‡æ–°å¤„ç†ï¼Œæ¸…ç©ºåˆ†æå†…å®¹
                if reason == 'DATE_REPROCESS':
                    filing.unified_analysis = None
                    filing.analysis_version = None
                
                db.commit()
                
                # åŠ å…¥å¤„ç†é˜Ÿåˆ—
                await reprocess_filing(filing.id)
                
                display_ticker = get_display_ticker(filing)
                print(f"  [{i}/{len(filings_to_process)}] âœ… {display_ticker} {filing.filing_type.value} "
                      f"(ID: {filing.id}) å·²åŠ å…¥é˜Ÿåˆ—")
                
                # æ¯5ä¸ªæš‚åœä¸€ä¸‹ï¼Œé¿å…è¿‡è½½
                if i % 5 == 0:
                    await asyncio.sleep(1)
                    
            except Exception as e:
                display_ticker = get_display_ticker(filing)
                print(f"  [{i}/{len(filings_to_process)}] âŒ {display_ticker} å¤„ç†å¤±è´¥: {e}")
        
        print("\n" + "="*80)
        print("âœ… æ‰€æœ‰è´¢æŠ¥å·²åŠ å…¥å¤„ç†é˜Ÿåˆ—ï¼")
        print("="*80)
        print("\nğŸ“Š åç»­ç›‘æ§:")
        print("  1. æŸ¥çœ‹çŠ¶æ€: python scripts/check_filing_status.py")
        print("  2. æŸ¥çœ‹æ—¥å¿—: tail -f logs/fintellic.log | grep -E 'ERROR|WARNING|succeeded'")
        print("  3. æŸ¥çœ‹Celery: tail -f celery_worker.log")
        print("  4. æŸ¥çœ‹æ•°æ®åº“:")
        print("     psql fintellic_db -c \"SELECT id, ticker, filing_type, status, error_message FROM filings WHERE status != 'completed' ORDER BY id DESC LIMIT 20;\"")
        
    except Exception as e:
        logger.error(f"Error in main: {e}")
        import traceback
        traceback.print_exc()
    finally:
        db.close()


if __name__ == "__main__":
    asyncio.run(main())